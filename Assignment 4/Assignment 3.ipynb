{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"E:/scrapedimages/train/\"\n",
    "CATEGORIES = [\"saree\",\"Tshirts\",\"shirts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 240\n",
    "\n",
    "data=[]\n",
    "\n",
    "num=0\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        rows,cols,ht=img_array.shape\n",
    "        matrix=cv2.getRotationMatrix2D((rows/2,cols/2),30,0.99)\n",
    "        new_img=cv2.warpAffine(img_array,matrix,(cols,rows))\n",
    "        cv2.imwrite(os.path.join(path, \"rotated_img_\"+str(num)+\".jpg\"),new_img)\n",
    "        intensity_matrix=np.ones(img_array.shape,dtype =\"uint8\")*100\n",
    "        bright= cv2.add(img_array, intensity_matrix)\n",
    "        dark= cv2.subtract(img_array, intensity_matrix)\n",
    "        cv2.imwrite(os.path.join(path, \"Brightend_img_\"+str(num)+\".jpg\"),bright)\n",
    "        cv2.imwrite(os.path.join(path, \"Darkend_img_\"+str(num)+\".jpg\"),dark)\n",
    "        fliphor=cv2.flip(img_array,0)\n",
    "        flipver=cv2.flip(img_array,1)\n",
    "        flipbot=cv2.flip(img_array,-1)\n",
    "        cv2.imwrite(os.path.join(path, \"Horizontalflip_img_\"+str(num)+\".jpg\"),fliphor)\n",
    "        cv2.imwrite(os.path.join(path, \"verticalflip_img_\"+str(num)+\".jpg\"),flipver)\n",
    "        cv2.imwrite(os.path.join(path, \"Bothflip_img_\"+str(num)+\".jpg\"),flipbot)\n",
    "        kernal_sharpening = np.array([[-1,-1,-1],\n",
    "                                     [-1, 9,-1],\n",
    "                                     [-1,-1,-1]])\n",
    "        sharpend=cv2.filter2D(img_array, -1, kernal_sharpening)\n",
    "        cv2.imwrite(os.path.join(path, \"Sharpend_img_\"+str(num)+\".jpg\"),sharpend)\n",
    "        \n",
    "        num=num+1\n",
    "        \n",
    "\n",
    "        data.append([img_array, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 120\n",
    "\n",
    "data=[]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([img_array, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2554, 120, 120, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (5,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (5,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, input_shape=(120,120,3), activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2298 samples, validate on 256 samples\n",
      "Epoch 1/5\n",
      "2298/2298 [==============================] - ETA: 53s - loss: 1.1063 - accuracy: 0.218 - ETA: 48s - loss: 3.5522 - accuracy: 0.343 - ETA: 46s - loss: 2.9993 - accuracy: 0.322 - ETA: 45s - loss: 2.5448 - accuracy: 0.296 - ETA: 43s - loss: 2.2520 - accuracy: 0.350 - ETA: 43s - loss: 2.0555 - accuracy: 0.380 - ETA: 42s - loss: 1.9180 - accuracy: 0.370 - ETA: 41s - loss: 1.8146 - accuracy: 0.382 - ETA: 40s - loss: 1.7327 - accuracy: 0.388 - ETA: 39s - loss: 1.6650 - accuracy: 0.393 - ETA: 39s - loss: 1.6073 - accuracy: 0.397 - ETA: 38s - loss: 1.5590 - accuracy: 0.398 - ETA: 37s - loss: 1.5131 - accuracy: 0.406 - ETA: 37s - loss: 1.4889 - accuracy: 0.415 - ETA: 36s - loss: 1.4481 - accuracy: 0.431 - ETA: 36s - loss: 1.4184 - accuracy: 0.429 - ETA: 35s - loss: 1.3843 - accuracy: 0.443 - ETA: 34s - loss: 1.3669 - accuracy: 0.449 - ETA: 34s - loss: 1.3502 - accuracy: 0.445 - ETA: 33s - loss: 1.3318 - accuracy: 0.451 - ETA: 33s - loss: 1.3113 - accuracy: 0.459 - ETA: 32s - loss: 1.2910 - accuracy: 0.467 - ETA: 31s - loss: 1.2753 - accuracy: 0.467 - ETA: 30s - loss: 1.2557 - accuracy: 0.476 - ETA: 30s - loss: 1.2403 - accuracy: 0.483 - ETA: 29s - loss: 1.2236 - accuracy: 0.490 - ETA: 28s - loss: 1.2178 - accuracy: 0.490 - ETA: 28s - loss: 1.2053 - accuracy: 0.495 - ETA: 27s - loss: 1.1998 - accuracy: 0.492 - ETA: 27s - loss: 1.1961 - accuracy: 0.488 - ETA: 26s - loss: 1.1843 - accuracy: 0.492 - ETA: 25s - loss: 1.1682 - accuracy: 0.503 - ETA: 25s - loss: 1.1631 - accuracy: 0.502 - ETA: 24s - loss: 1.1496 - accuracy: 0.507 - ETA: 23s - loss: 1.1347 - accuracy: 0.512 - ETA: 23s - loss: 1.1229 - accuracy: 0.517 - ETA: 22s - loss: 1.1121 - accuracy: 0.523 - ETA: 21s - loss: 1.1029 - accuracy: 0.530 - ETA: 21s - loss: 1.0891 - accuracy: 0.537 - ETA: 20s - loss: 1.0738 - accuracy: 0.545 - ETA: 19s - loss: 1.0622 - accuracy: 0.548 - ETA: 19s - loss: 1.0491 - accuracy: 0.554 - ETA: 18s - loss: 1.0365 - accuracy: 0.559 - ETA: 18s - loss: 1.0265 - accuracy: 0.562 - ETA: 17s - loss: 1.0208 - accuracy: 0.563 - ETA: 16s - loss: 1.0114 - accuracy: 0.567 - ETA: 16s - loss: 0.9995 - accuracy: 0.573 - ETA: 15s - loss: 0.9915 - accuracy: 0.576 - ETA: 14s - loss: 0.9825 - accuracy: 0.581 - ETA: 14s - loss: 0.9722 - accuracy: 0.586 - ETA: 13s - loss: 0.9656 - accuracy: 0.588 - ETA: 12s - loss: 0.9585 - accuracy: 0.590 - ETA: 12s - loss: 0.9481 - accuracy: 0.595 - ETA: 11s - loss: 0.9421 - accuracy: 0.599 - ETA: 10s - loss: 0.9356 - accuracy: 0.602 - ETA: 10s - loss: 0.9315 - accuracy: 0.604 - ETA: 9s - loss: 0.9256 - accuracy: 0.605 - ETA: 8s - loss: 0.9194 - accuracy: 0.60 - ETA: 8s - loss: 0.9106 - accuracy: 0.61 - ETA: 7s - loss: 0.9027 - accuracy: 0.61 - ETA: 7s - loss: 0.8968 - accuracy: 0.61 - ETA: 6s - loss: 0.8927 - accuracy: 0.62 - ETA: 5s - loss: 0.8861 - accuracy: 0.62 - ETA: 5s - loss: 0.8785 - accuracy: 0.62 - ETA: 4s - loss: 0.8714 - accuracy: 0.63 - ETA: 3s - loss: 0.8657 - accuracy: 0.63 - ETA: 3s - loss: 0.8593 - accuracy: 0.63 - ETA: 2s - loss: 0.8543 - accuracy: 0.63 - ETA: 1s - loss: 0.8475 - accuracy: 0.63 - ETA: 1s - loss: 0.8405 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.64 - 50s 22ms/step - loss: 0.8282 - accuracy: 0.6466 - val_loss: 0.4163 - val_accuracy: 0.8398\n",
      "Epoch 2/5\n",
      "2298/2298 [==============================] - ETA: 53s - loss: 0.3885 - accuracy: 0.843 - ETA: 52s - loss: 0.2683 - accuracy: 0.906 - ETA: 52s - loss: 0.3096 - accuracy: 0.864 - ETA: 51s - loss: 0.3020 - accuracy: 0.875 - ETA: 49s - loss: 0.3250 - accuracy: 0.881 - ETA: 48s - loss: 0.3005 - accuracy: 0.895 - ETA: 47s - loss: 0.2974 - accuracy: 0.897 - ETA: 46s - loss: 0.3025 - accuracy: 0.886 - ETA: 45s - loss: 0.3145 - accuracy: 0.878 - ETA: 44s - loss: 0.3036 - accuracy: 0.884 - ETA: 43s - loss: 0.3121 - accuracy: 0.880 - ETA: 42s - loss: 0.3044 - accuracy: 0.882 - ETA: 41s - loss: 0.3186 - accuracy: 0.879 - ETA: 41s - loss: 0.3187 - accuracy: 0.879 - ETA: 40s - loss: 0.3174 - accuracy: 0.883 - ETA: 40s - loss: 0.3108 - accuracy: 0.884 - ETA: 39s - loss: 0.3074 - accuracy: 0.884 - ETA: 38s - loss: 0.2998 - accuracy: 0.887 - ETA: 37s - loss: 0.2971 - accuracy: 0.888 - ETA: 36s - loss: 0.2945 - accuracy: 0.890 - ETA: 35s - loss: 0.2950 - accuracy: 0.888 - ETA: 35s - loss: 0.2949 - accuracy: 0.886 - ETA: 34s - loss: 0.2920 - accuracy: 0.889 - ETA: 33s - loss: 0.2911 - accuracy: 0.889 - ETA: 32s - loss: 0.2878 - accuracy: 0.891 - ETA: 32s - loss: 0.2858 - accuracy: 0.891 - ETA: 31s - loss: 0.2865 - accuracy: 0.888 - ETA: 30s - loss: 0.2833 - accuracy: 0.890 - ETA: 30s - loss: 0.2826 - accuracy: 0.890 - ETA: 29s - loss: 0.2985 - accuracy: 0.882 - ETA: 29s - loss: 0.2934 - accuracy: 0.885 - ETA: 28s - loss: 0.2911 - accuracy: 0.884 - ETA: 27s - loss: 0.2894 - accuracy: 0.885 - ETA: 27s - loss: 0.2874 - accuracy: 0.886 - ETA: 26s - loss: 0.2917 - accuracy: 0.884 - ETA: 26s - loss: 0.2933 - accuracy: 0.884 - ETA: 25s - loss: 0.2912 - accuracy: 0.886 - ETA: 24s - loss: 0.2905 - accuracy: 0.886 - ETA: 23s - loss: 0.2904 - accuracy: 0.885 - ETA: 23s - loss: 0.2886 - accuracy: 0.886 - ETA: 22s - loss: 0.2887 - accuracy: 0.885 - ETA: 21s - loss: 0.2927 - accuracy: 0.882 - ETA: 20s - loss: 0.2945 - accuracy: 0.880 - ETA: 20s - loss: 0.2949 - accuracy: 0.881 - ETA: 19s - loss: 0.2943 - accuracy: 0.881 - ETA: 18s - loss: 0.2951 - accuracy: 0.882 - ETA: 17s - loss: 0.2938 - accuracy: 0.883 - ETA: 17s - loss: 0.2931 - accuracy: 0.882 - ETA: 16s - loss: 0.2939 - accuracy: 0.882 - ETA: 15s - loss: 0.2923 - accuracy: 0.883 - ETA: 15s - loss: 0.2900 - accuracy: 0.885 - ETA: 14s - loss: 0.2899 - accuracy: 0.885 - ETA: 13s - loss: 0.2885 - accuracy: 0.886 - ETA: 12s - loss: 0.2867 - accuracy: 0.887 - ETA: 12s - loss: 0.2890 - accuracy: 0.886 - ETA: 11s - loss: 0.2867 - accuracy: 0.887 - ETA: 10s - loss: 0.2864 - accuracy: 0.887 - ETA: 10s - loss: 0.2840 - accuracy: 0.889 - ETA: 9s - loss: 0.2832 - accuracy: 0.889 - ETA: 8s - loss: 0.2816 - accuracy: 0.89 - ETA: 7s - loss: 0.2817 - accuracy: 0.88 - ETA: 7s - loss: 0.2807 - accuracy: 0.89 - ETA: 6s - loss: 0.2808 - accuracy: 0.89 - ETA: 5s - loss: 0.2795 - accuracy: 0.89 - ETA: 4s - loss: 0.2779 - accuracy: 0.89 - ETA: 4s - loss: 0.2784 - accuracy: 0.89 - ETA: 3s - loss: 0.2782 - accuracy: 0.89 - ETA: 2s - loss: 0.2785 - accuracy: 0.88 - ETA: 2s - loss: 0.2786 - accuracy: 0.88 - ETA: 1s - loss: 0.2772 - accuracy: 0.89 - ETA: 0s - loss: 0.2763 - accuracy: 0.89 - 53s 23ms/step - loss: 0.2774 - accuracy: 0.8912 - val_loss: 0.3289 - val_accuracy: 0.8672\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298/2298 [==============================] - ETA: 47s - loss: 0.2130 - accuracy: 0.937 - ETA: 47s - loss: 0.1863 - accuracy: 0.953 - ETA: 46s - loss: 0.1622 - accuracy: 0.947 - ETA: 46s - loss: 0.1961 - accuracy: 0.921 - ETA: 46s - loss: 0.2014 - accuracy: 0.918 - ETA: 45s - loss: 0.2353 - accuracy: 0.901 - ETA: 45s - loss: 0.2198 - accuracy: 0.915 - ETA: 44s - loss: 0.2153 - accuracy: 0.914 - ETA: 43s - loss: 0.2044 - accuracy: 0.920 - ETA: 42s - loss: 0.2119 - accuracy: 0.921 - ETA: 42s - loss: 0.2043 - accuracy: 0.923 - ETA: 41s - loss: 0.2011 - accuracy: 0.924 - ETA: 40s - loss: 0.1995 - accuracy: 0.925 - ETA: 39s - loss: 0.1996 - accuracy: 0.919 - ETA: 39s - loss: 0.2027 - accuracy: 0.918 - ETA: 38s - loss: 0.1993 - accuracy: 0.919 - ETA: 37s - loss: 0.1967 - accuracy: 0.921 - ETA: 37s - loss: 0.1964 - accuracy: 0.921 - ETA: 36s - loss: 0.2070 - accuracy: 0.919 - ETA: 35s - loss: 0.2036 - accuracy: 0.918 - ETA: 34s - loss: 0.2032 - accuracy: 0.919 - ETA: 34s - loss: 0.2034 - accuracy: 0.919 - ETA: 33s - loss: 0.2011 - accuracy: 0.918 - ETA: 32s - loss: 0.1988 - accuracy: 0.919 - ETA: 32s - loss: 0.1970 - accuracy: 0.920 - ETA: 31s - loss: 0.1950 - accuracy: 0.920 - ETA: 30s - loss: 0.1966 - accuracy: 0.920 - ETA: 30s - loss: 0.1944 - accuracy: 0.919 - ETA: 29s - loss: 0.2014 - accuracy: 0.917 - ETA: 28s - loss: 0.1989 - accuracy: 0.916 - ETA: 28s - loss: 0.1959 - accuracy: 0.917 - ETA: 27s - loss: 0.2022 - accuracy: 0.916 - ETA: 26s - loss: 0.2025 - accuracy: 0.913 - ETA: 26s - loss: 0.2038 - accuracy: 0.913 - ETA: 25s - loss: 0.2021 - accuracy: 0.914 - ETA: 24s - loss: 0.2026 - accuracy: 0.915 - ETA: 24s - loss: 0.1997 - accuracy: 0.918 - ETA: 23s - loss: 0.1983 - accuracy: 0.919 - ETA: 22s - loss: 0.1963 - accuracy: 0.919 - ETA: 21s - loss: 0.1971 - accuracy: 0.919 - ETA: 21s - loss: 0.2018 - accuracy: 0.916 - ETA: 20s - loss: 0.2059 - accuracy: 0.917 - ETA: 19s - loss: 0.2061 - accuracy: 0.917 - ETA: 19s - loss: 0.2055 - accuracy: 0.917 - ETA: 18s - loss: 0.2079 - accuracy: 0.916 - ETA: 17s - loss: 0.2062 - accuracy: 0.917 - ETA: 17s - loss: 0.2070 - accuracy: 0.918 - ETA: 16s - loss: 0.2075 - accuracy: 0.918 - ETA: 15s - loss: 0.2073 - accuracy: 0.918 - ETA: 14s - loss: 0.2086 - accuracy: 0.917 - ETA: 14s - loss: 0.2075 - accuracy: 0.917 - ETA: 13s - loss: 0.2076 - accuracy: 0.917 - ETA: 12s - loss: 0.2056 - accuracy: 0.918 - ETA: 12s - loss: 0.2056 - accuracy: 0.917 - ETA: 11s - loss: 0.2037 - accuracy: 0.918 - ETA: 10s - loss: 0.2033 - accuracy: 0.919 - ETA: 10s - loss: 0.2040 - accuracy: 0.918 - ETA: 9s - loss: 0.2051 - accuracy: 0.918 - ETA: 8s - loss: 0.2071 - accuracy: 0.91 - ETA: 8s - loss: 0.2074 - accuracy: 0.91 - ETA: 7s - loss: 0.2091 - accuracy: 0.91 - ETA: 6s - loss: 0.2067 - accuracy: 0.91 - ETA: 6s - loss: 0.2057 - accuracy: 0.91 - ETA: 5s - loss: 0.2037 - accuracy: 0.91 - ETA: 4s - loss: 0.2020 - accuracy: 0.92 - ETA: 3s - loss: 0.2018 - accuracy: 0.92 - ETA: 3s - loss: 0.2018 - accuracy: 0.92 - ETA: 2s - loss: 0.2016 - accuracy: 0.92 - ETA: 1s - loss: 0.2030 - accuracy: 0.92 - ETA: 1s - loss: 0.2028 - accuracy: 0.92 - ETA: 0s - loss: 0.2037 - accuracy: 0.92 - 50s 22ms/step - loss: 0.2034 - accuracy: 0.9204 - val_loss: 0.2629 - val_accuracy: 0.9258\n",
      "Epoch 4/5\n",
      "2298/2298 [==============================] - ETA: 48s - loss: 0.1634 - accuracy: 0.906 - ETA: 49s - loss: 0.2035 - accuracy: 0.906 - ETA: 48s - loss: 0.1492 - accuracy: 0.937 - ETA: 48s - loss: 0.1274 - accuracy: 0.953 - ETA: 47s - loss: 0.1215 - accuracy: 0.956 - ETA: 46s - loss: 0.1189 - accuracy: 0.953 - ETA: 45s - loss: 0.1108 - accuracy: 0.959 - ETA: 44s - loss: 0.1124 - accuracy: 0.953 - ETA: 43s - loss: 0.1206 - accuracy: 0.944 - ETA: 42s - loss: 0.1139 - accuracy: 0.950 - ETA: 41s - loss: 0.1138 - accuracy: 0.946 - ETA: 41s - loss: 0.1348 - accuracy: 0.937 - ETA: 40s - loss: 0.1293 - accuracy: 0.942 - ETA: 39s - loss: 0.1262 - accuracy: 0.944 - ETA: 38s - loss: 0.1247 - accuracy: 0.947 - ETA: 38s - loss: 0.1262 - accuracy: 0.947 - ETA: 37s - loss: 0.1241 - accuracy: 0.950 - ETA: 36s - loss: 0.1306 - accuracy: 0.947 - ETA: 36s - loss: 0.1260 - accuracy: 0.950 - ETA: 35s - loss: 0.1240 - accuracy: 0.951 - ETA: 34s - loss: 0.1230 - accuracy: 0.952 - ETA: 33s - loss: 0.1251 - accuracy: 0.953 - ETA: 33s - loss: 0.1231 - accuracy: 0.955 - ETA: 32s - loss: 0.1292 - accuracy: 0.955 - ETA: 31s - loss: 0.1269 - accuracy: 0.957 - ETA: 31s - loss: 0.1239 - accuracy: 0.959 - ETA: 30s - loss: 0.1321 - accuracy: 0.956 - ETA: 29s - loss: 0.1284 - accuracy: 0.957 - ETA: 29s - loss: 0.1248 - accuracy: 0.959 - ETA: 28s - loss: 0.1234 - accuracy: 0.959 - ETA: 27s - loss: 0.1232 - accuracy: 0.958 - ETA: 27s - loss: 0.1269 - accuracy: 0.958 - ETA: 26s - loss: 0.1283 - accuracy: 0.958 - ETA: 26s - loss: 0.1268 - accuracy: 0.958 - ETA: 25s - loss: 0.1284 - accuracy: 0.957 - ETA: 24s - loss: 0.1272 - accuracy: 0.957 - ETA: 24s - loss: 0.1259 - accuracy: 0.957 - ETA: 23s - loss: 0.1262 - accuracy: 0.956 - ETA: 22s - loss: 0.1251 - accuracy: 0.956 - ETA: 22s - loss: 0.1235 - accuracy: 0.957 - ETA: 21s - loss: 0.1230 - accuracy: 0.958 - ETA: 20s - loss: 0.1210 - accuracy: 0.959 - ETA: 20s - loss: 0.1219 - accuracy: 0.958 - ETA: 19s - loss: 0.1207 - accuracy: 0.958 - ETA: 18s - loss: 0.1195 - accuracy: 0.959 - ETA: 18s - loss: 0.1189 - accuracy: 0.958 - ETA: 17s - loss: 0.1186 - accuracy: 0.958 - ETA: 16s - loss: 0.1178 - accuracy: 0.959 - ETA: 16s - loss: 0.1171 - accuracy: 0.959 - ETA: 15s - loss: 0.1164 - accuracy: 0.959 - ETA: 14s - loss: 0.1149 - accuracy: 0.960 - ETA: 14s - loss: 0.1137 - accuracy: 0.960 - ETA: 13s - loss: 0.1123 - accuracy: 0.961 - ETA: 12s - loss: 0.1139 - accuracy: 0.961 - ETA: 12s - loss: 0.1130 - accuracy: 0.961 - ETA: 11s - loss: 0.1126 - accuracy: 0.961 - ETA: 10s - loss: 0.1111 - accuracy: 0.962 - ETA: 9s - loss: 0.1098 - accuracy: 0.962 - ETA: 9s - loss: 0.1106 - accuracy: 0.96 - ETA: 8s - loss: 0.1110 - accuracy: 0.96 - ETA: 7s - loss: 0.1103 - accuracy: 0.96 - ETA: 7s - loss: 0.1106 - accuracy: 0.96 - ETA: 6s - loss: 0.1127 - accuracy: 0.96 - ETA: 5s - loss: 0.1125 - accuracy: 0.96 - ETA: 4s - loss: 0.1122 - accuracy: 0.96 - ETA: 4s - loss: 0.1111 - accuracy: 0.96 - ETA: 3s - loss: 0.1099 - accuracy: 0.96 - ETA: 2s - loss: 0.1104 - accuracy: 0.96 - ETA: 2s - loss: 0.1180 - accuracy: 0.96 - ETA: 1s - loss: 0.1188 - accuracy: 0.96 - ETA: 0s - loss: 0.1178 - accuracy: 0.96 - 53s 23ms/step - loss: 0.1183 - accuracy: 0.9613 - val_loss: 0.4058 - val_accuracy: 0.8789\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298/2298 [==============================] - ETA: 46s - loss: 0.1099 - accuracy: 0.968 - ETA: 46s - loss: 0.0717 - accuracy: 0.984 - ETA: 46s - loss: 0.0855 - accuracy: 0.979 - ETA: 45s - loss: 0.0701 - accuracy: 0.984 - ETA: 45s - loss: 0.0611 - accuracy: 0.987 - ETA: 44s - loss: 0.0574 - accuracy: 0.989 - ETA: 43s - loss: 0.0810 - accuracy: 0.977 - ETA: 43s - loss: 0.0770 - accuracy: 0.976 - ETA: 42s - loss: 0.0740 - accuracy: 0.979 - ETA: 41s - loss: 0.0781 - accuracy: 0.975 - ETA: 41s - loss: 0.0817 - accuracy: 0.974 - ETA: 40s - loss: 0.0865 - accuracy: 0.974 - ETA: 40s - loss: 0.0839 - accuracy: 0.973 - ETA: 39s - loss: 0.0936 - accuracy: 0.966 - ETA: 39s - loss: 0.0938 - accuracy: 0.966 - ETA: 38s - loss: 0.0996 - accuracy: 0.964 - ETA: 38s - loss: 0.0971 - accuracy: 0.966 - ETA: 37s - loss: 0.0980 - accuracy: 0.965 - ETA: 36s - loss: 0.0973 - accuracy: 0.965 - ETA: 36s - loss: 0.0946 - accuracy: 0.967 - ETA: 35s - loss: 0.0928 - accuracy: 0.968 - ETA: 34s - loss: 0.0902 - accuracy: 0.970 - ETA: 33s - loss: 0.0928 - accuracy: 0.968 - ETA: 33s - loss: 0.0911 - accuracy: 0.970 - ETA: 32s - loss: 0.0905 - accuracy: 0.971 - ETA: 31s - loss: 0.0879 - accuracy: 0.972 - ETA: 31s - loss: 0.0857 - accuracy: 0.973 - ETA: 30s - loss: 0.0857 - accuracy: 0.973 - ETA: 29s - loss: 0.0843 - accuracy: 0.974 - ETA: 28s - loss: 0.0855 - accuracy: 0.974 - ETA: 28s - loss: 0.0844 - accuracy: 0.973 - ETA: 27s - loss: 0.0890 - accuracy: 0.972 - ETA: 26s - loss: 0.0873 - accuracy: 0.973 - ETA: 26s - loss: 0.0853 - accuracy: 0.974 - ETA: 25s - loss: 0.0834 - accuracy: 0.975 - ETA: 24s - loss: 0.0827 - accuracy: 0.974 - ETA: 23s - loss: 0.0828 - accuracy: 0.974 - ETA: 23s - loss: 0.0816 - accuracy: 0.975 - ETA: 22s - loss: 0.0823 - accuracy: 0.975 - ETA: 21s - loss: 0.0808 - accuracy: 0.975 - ETA: 21s - loss: 0.0791 - accuracy: 0.976 - ETA: 20s - loss: 0.0778 - accuracy: 0.976 - ETA: 19s - loss: 0.0833 - accuracy: 0.976 - ETA: 19s - loss: 0.0826 - accuracy: 0.976 - ETA: 18s - loss: 0.0838 - accuracy: 0.975 - ETA: 17s - loss: 0.0828 - accuracy: 0.976 - ETA: 17s - loss: 0.0815 - accuracy: 0.976 - ETA: 16s - loss: 0.0810 - accuracy: 0.976 - ETA: 15s - loss: 0.0797 - accuracy: 0.977 - ETA: 15s - loss: 0.0811 - accuracy: 0.976 - ETA: 14s - loss: 0.0799 - accuracy: 0.977 - ETA: 13s - loss: 0.0790 - accuracy: 0.977 - ETA: 13s - loss: 0.0779 - accuracy: 0.978 - ETA: 12s - loss: 0.0779 - accuracy: 0.978 - ETA: 11s - loss: 0.0767 - accuracy: 0.978 - ETA: 10s - loss: 0.0762 - accuracy: 0.978 - ETA: 10s - loss: 0.0752 - accuracy: 0.979 - ETA: 9s - loss: 0.0746 - accuracy: 0.979 - ETA: 8s - loss: 0.0736 - accuracy: 0.97 - ETA: 8s - loss: 0.0731 - accuracy: 0.98 - ETA: 7s - loss: 0.0733 - accuracy: 0.98 - ETA: 6s - loss: 0.0726 - accuracy: 0.98 - ETA: 6s - loss: 0.0716 - accuracy: 0.98 - ETA: 5s - loss: 0.0708 - accuracy: 0.98 - ETA: 4s - loss: 0.0703 - accuracy: 0.98 - ETA: 4s - loss: 0.0695 - accuracy: 0.98 - ETA: 3s - loss: 0.0686 - accuracy: 0.98 - ETA: 2s - loss: 0.0704 - accuracy: 0.98 - ETA: 1s - loss: 0.0694 - accuracy: 0.98 - ETA: 1s - loss: 0.0689 - accuracy: 0.98 - ETA: 0s - loss: 0.0686 - accuracy: 0.98 - 51s 22ms/step - loss: 0.0680 - accuracy: 0.9813 - val_loss: 0.2268 - val_accuracy: 0.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21247695bc8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(filepath):\n",
    "    IMG_SIZE=120\n",
    "    img_array1 = cv2.imread(filepath)\n",
    "    new_array1 = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE))\n",
    "    return new_array1.reshape(1,IMG_SIZE, IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saree\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict([prep('E:/scrapedimages/test/saree/5.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
