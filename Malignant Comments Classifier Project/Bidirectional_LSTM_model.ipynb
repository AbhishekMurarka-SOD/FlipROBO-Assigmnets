{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtnctpWDGB4V",
    "outputId": "c5ab2340-8e78-48ff-e981-c6c62ac5a22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "## importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ab9XLGEYGFfJ"
   },
   "outputs": [],
   "source": [
    "path='/content/drive/MyDrive/Malignant Comments Classifier Project/train.csv'\n",
    "data=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F__sTsElGXMV"
   },
   "outputs": [],
   "source": [
    "df_class0 = data.loc[(data['malignant'] == 0) & (data['highly_malignant'] == 0) & (data['rude'] == 0) & (data['threat'] == 0) & (data['abuse'] == 0) & (data['loathe'] == 0)]\n",
    "df_class1 = data[(data['malignant'] == 1) | (data['highly_malignant'] == 1) | (data['rude'] == 1) | (data['threat'] == 1) | (data['abuse'] == 1) | (data['loathe'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UjSXU3cXGdiC"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_class0_downsampled = resample(df_class0, \n",
    "                                 replace=False,    \n",
    "                                 n_samples=16225,     \n",
    "                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "-lovqf8OGhkO",
    "outputId": "1c6b5f94-eac6-4e84-8d68-a9c49653c6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>malignant</th>\n",
       "      <th>highly_malignant</th>\n",
       "      <th>rude</th>\n",
       "      <th>threat</th>\n",
       "      <th>abuse</th>\n",
       "      <th>loathe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46733</th>\n",
       "      <td>7ce2c22fd3409fbb</td>\n",
       "      <td>\"\\n\\nOh, don't worry about me, Sandstein. I'm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110326</th>\n",
       "      <td>4e366a5778e1b5b4</td>\n",
       "      <td>Are you trying to dispute that fact?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76687</th>\n",
       "      <td>cd62283cfe430f72</td>\n",
       "      <td>SWOT analysis \\n\\nThis source – Align Technolo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36231</th>\n",
       "      <td>60cdd48fb71157e6</td>\n",
       "      <td>cover \\n\\nso, do we want a current or older co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21514</th>\n",
       "      <td>38b04f0b55ac0c31</td>\n",
       "      <td>P.S. It's probably worth setting up a template...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>4f4558c105fd8e68</td>\n",
       "      <td>I dont, however Gun Powder Ma, would you mind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90273</th>\n",
       "      <td>f192a8ad369f691f</td>\n",
       "      <td>\"\\n\\n My Draft of Kaithal honour killing case ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120264</th>\n",
       "      <td>8339e6cc7623b3f2</td>\n",
       "      <td>tHANX FOR THE TIP ILL DO SO AS SOON AS I CAN!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158396</th>\n",
       "      <td>ed23f1af8f561480</td>\n",
       "      <td>\"\\n\\nTrivia?\\n\"\"Lightfoot is referenced in man...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111060</th>\n",
       "      <td>52250dc4a4718a01</td>\n",
       "      <td>OMG. I searched in Orens book using Amazon. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16225 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  ... loathe\n",
       "46733   7ce2c22fd3409fbb  ...      0\n",
       "110326  4e366a5778e1b5b4  ...      0\n",
       "76687   cd62283cfe430f72  ...      0\n",
       "36231   60cdd48fb71157e6  ...      0\n",
       "21514   38b04f0b55ac0c31  ...      0\n",
       "...                  ...  ...    ...\n",
       "29862   4f4558c105fd8e68  ...      0\n",
       "90273   f192a8ad369f691f  ...      0\n",
       "120264  8339e6cc7623b3f2  ...      0\n",
       "158396  ed23f1af8f561480  ...      0\n",
       "111060  52250dc4a4718a01  ...      0\n",
       "\n",
       "[16225 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class0_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZF6oNdubGjc2"
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df_class0_downsampled,df_class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvxCw_xnGoHm",
    "outputId": "9c6dce92-30fc-4db4-e125-0e8b41c71601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing more important libraries\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import nltk\n",
    "import ast\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import sentiwordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e6wEcdFOGqE9"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "def clean_text(text):\n",
    "    text=str(text)\n",
    "    text = text.lower()\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', text)\n",
    "    rem_num = re.sub('[0-9]+', '', text)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bq4Yh6H9GtOE",
    "outputId": "6c665bb2-7ae9-49f5-9125-fcc3e27d1d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worry sandstein strong opinion well editing wikipedia personal benefit coi unfinished business articles arbitration sanctions rfar clarification dispute last block ostensibly sanction hope resolved without much fuss hand hoped past well control others respond understand recommendation see well motivated thanks',\n",
       "       'trying dispute fact',\n",
       "       'swot analysis source align technology inc swot analysis used times indication find whether primary source assume going remove anything sourced leaving note case objections talk',\n",
       "       ...,\n",
       "       'absurd edits absurd edits great white shark total vandalism sexual edit fucking bullshit like spam useful encyclopedia stop bullshit admins everywhere choice stop bullshit else blocked permanently user factualman',\n",
       "       'hey listen ever delete edits ever annoyed wwe roster confirmed stupid ass deletes write stop please stop work wwe games stop deleting peoples shit get wrong others get wrong let get hang eventually stick ass gonna delete please insert roster shit confirmed god stupid',\n",
       "       'going keep posting stuff deleted fucking site closes fun stupid ass bitch ever delete anything fuckin hore like said hell'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = df['comment_text'].values\n",
    "y_list = [\"malignant\", \"highly_malignant\", \"rude\", \"threat\", \"abuse\",\t\"loathe\"]\n",
    "y = df[y_list].values\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ya_XfxTNIHfq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iB7NgXvxImES"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "seq = tokenizer.texts_to_sequences(comments)\n",
    "pad = sequence.pad_sequences(seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNN0L0YQIuGj",
    "outputId": "940b363e-43ff-4b26-debd-78074b189a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 160)               133760    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                12880     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 486       \n",
      "=================================================================\n",
      "Total params: 2,707,126\n",
      "Trainable params: 2,707,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "\n",
    "def model_add():\n",
    "    inputs = Input(shape=(100, ))\n",
    "    x = Embedding(20000, 128)(inputs)\n",
    "    x = Bidirectional(LSTM(80))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(80, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = model_add()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dmXXg5VI_Lx",
    "outputId": "85dec363-a194-49c0-8127-85f26e798406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "913/913 [==============================] - 145s 159ms/step - loss: 0.2139 - accuracy: 0.9404 - val_loss: 0.3442 - val_accuracy: 0.9414\n",
      "Epoch 2/5\n",
      "913/913 [==============================] - 145s 159ms/step - loss: 0.1556 - accuracy: 0.9517 - val_loss: 0.3314 - val_accuracy: 0.9411\n",
      "Epoch 3/5\n",
      "913/913 [==============================] - 144s 158ms/step - loss: 0.1308 - accuracy: 0.9220 - val_loss: 0.3548 - val_accuracy: 0.9381\n",
      "Epoch 4/5\n",
      "913/913 [==============================] - 144s 158ms/step - loss: 0.1105 - accuracy: 0.8208 - val_loss: 0.3981 - val_accuracy: 0.9297\n",
      "Epoch 5/5\n",
      "913/913 [==============================] - 144s 158ms/step - loss: 0.0918 - accuracy: 0.7183 - val_loss: 0.4200 - val_accuracy: 0.8508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f26e7e061d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "model.fit(pad, y, batch_size=32, epochs=5, validation_split=0.1, callbacks=early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6DjEjqPbJJzu"
   },
   "outputs": [],
   "source": [
    "test_path='/content/drive/MyDrive/Malignant Comments Classifier Project/test.csv'\n",
    "test = pd.read_csv(test_path)\n",
    "test = test['comment_text'].values\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "test_pad = sequence.pad_sequences(test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvfmR-O1PJdm",
    "outputId": "a1070399-c597-423a-a6b0-d2ab412c2389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 84s 561ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([test_pad], batch_size=1024, verbose=1)\n",
    "predicted_submisson= pd.read_csv(test_path)\n",
    "predicted_submisson[y_list] = y_test\n",
    "predicted_submisson.to_csv('predicted_submisson.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qIvg-EzQJbt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bidirectional LSTM model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
